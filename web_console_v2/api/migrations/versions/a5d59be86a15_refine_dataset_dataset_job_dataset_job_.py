"""refine dataset/dataset_job/dataset_job_stage model

Revision ID: a5d59be86a15
Revises: b18d8fa7232d
Create Date: 2022-07-19 17:46:10.362827

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'a5d59be86a15'
down_revision = 'b18d8fa7232d'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('dataset_job_stages_v2',
    sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True, comment='deleted time'),
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False, comment='id of dataset job stage'),
    sa.Column('uuid', sa.String(length=255), nullable=False, comment='dataset job stage uuid'),
    sa.Column('name', sa.String(length=255), nullable=True, comment='dataset job stage name'),
    sa.Column('state', sa.Enum('PENDING', 'RUNNING', 'SUCCEEDED', 'FAILED', 'STOPPED', name='datasetjobstate', length=64, native_enum=False, create_constraint=False), nullable=False, comment='dataset job stage state'),
    sa.Column('project_id', sa.Integer(), nullable=False, comment='project id'),
    sa.Column('workflow_id', sa.Integer(), nullable=True, comment='relating workflow id'),
    sa.Column('dataset_job_id', sa.Integer(), nullable=False, comment='dataset_job id'),
    sa.Column('data_batch_id', sa.Integer(), nullable=False, comment='data_batch id'),
    sa.Column('event_time', sa.DateTime(timezone=True), nullable=True, comment='event_time of data upload'),
    sa.Column('global_configs', sa.Text(), nullable=True, comment='global configs of this stage including related participants only appear in coordinator'),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True, comment='created time'),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True, comment='updated time'),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True, comment='started_at'),
    sa.Column('finished_at', sa.DateTime(timezone=True), nullable=True, comment='finished_at'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('uuid', name='uniq_dataset_job_stage_uuid'),
    comment='dataset_job_stages_v2',
    mysql_charset='utf8mb4',
    mysql_engine='innodb'
    )
    op.add_column('data_batches_v2', sa.Column('name', sa.String(length=255), nullable=True, comment='data_batch name'))
    op.add_column('dataset_jobs_v2', sa.Column('time_range', sa.Interval(), nullable=True, comment='time_range to create new job_stage'))
    op.add_column('dataset_jobs_v2', sa.Column('event_time', sa.DateTime(timezone=True), nullable=True, comment='event_time for current data_batch'))
    op.add_column('dataset_jobs_v2', sa.Column('scheduler_state', sa.Enum('PENDING', 'RUNNABLE', 'STOPPED', name='datasetjobschedulerstate', length=64, native_enum=False, create_constraint=False), nullable=True, comment='dataset job scheduler state'))
    op.add_column('datasets_v2', sa.Column('store_format', sa.Enum('UNKNOWN', 'CSV', 'TFRECORDS', name='storeformat', length=32, native_enum=False, create_constraint=False), nullable=True, comment='dataset store format, like CSV, TFRECORDS, ...'))
    op.add_column('datasets_v2', sa.Column('import_type', sa.Enum('COPY', 'NO_COPY', name='importtype', length=64, native_enum=False, create_constraint=False), server_default='COPY', nullable=True, comment='import type'))
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('datasets_v2', 'import_type')
    op.drop_column('datasets_v2', 'store_format')
    op.drop_column('dataset_jobs_v2', 'scheduler_state')
    op.drop_column('dataset_jobs_v2', 'event_time')
    op.drop_column('dataset_jobs_v2', 'time_range')
    op.drop_column('data_batches_v2', 'name')
    op.drop_table('dataset_job_stages_v2')
    # ### end Alembic commands ###
